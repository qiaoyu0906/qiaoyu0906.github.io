{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59302f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202f0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import win32gui\n",
    "import win32con\n",
    "import ctypes\n",
    "from PIL import ImageGrab\n",
    "import win32com.client\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import win32api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb7c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASFW_ANY = -1  # 定义 ASFW_ANY 常量\n",
    "DWMWA_EXTENDED_FRAME_BOUNDS = 9  # 用于获取窗口的扩展边界\n",
    "\n",
    "def get_window_pos(name):\n",
    "    handle = win32gui.FindWindow(0, name)\n",
    "    # 获取窗口句柄\n",
    "    if handle == 0:\n",
    "        return None\n",
    "    else:\n",
    "        # 获取窗口扩展边界\n",
    "        rect = ctypes.wintypes.RECT()\n",
    "        ctypes.windll.dwmapi.DwmGetWindowAttribute(\n",
    "            ctypes.wintypes.HWND(handle),\n",
    "            ctypes.wintypes.DWORD(DWMWA_EXTENDED_FRAME_BOUNDS),\n",
    "            ctypes.byref(rect),\n",
    "            ctypes.sizeof(rect)\n",
    "        )\n",
    "        return (rect.left, rect.top, rect.right, rect.bottom), handle\n",
    "\n",
    "def allow_set_foreground_window():\n",
    "    # 允许当前进程设置前景窗口\n",
    "    asfw = ctypes.windll.user32.AllowSetForegroundWindow\n",
    "    asfw(ASFW_ANY)\n",
    "\n",
    "def fetch_image_first(window_name):\n",
    "    window_info = get_window_pos(window_name)\n",
    "    if window_info is None:\n",
    "        print(\"未找到指定窗口\")\n",
    "        return None\n",
    "    \n",
    "    (x1, y1, x2, y2), handle = window_info\n",
    "    # 发送还原最小化窗口的信息\n",
    "    win32gui.SendMessage(handle, win32con.WM_SYSCOMMAND, win32con.SC_RESTORE, 0)\n",
    "    # 等待窗口恢复\n",
    "    time.sleep(1)\n",
    "    # 允许设置前景窗口\n",
    "    allow_set_foreground_window()\n",
    "    \n",
    "    shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
    "    shell.SendKeys('%')\n",
    "    # 设为高亮\n",
    "    win32gui.SetForegroundWindow(handle)\n",
    "    # 等待窗口响应\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 检查窗口是否可见\n",
    "    if not win32gui.IsWindowVisible(handle):\n",
    "        print(\"窗口不可见\")\n",
    "        return None\n",
    "\n",
    "    # 再次获取整个窗口位置（包括标题栏和边框）\n",
    "    window_info = get_window_pos(window_name)\n",
    "    if window_info is None:\n",
    "        print(\"未找到指定窗口\")\n",
    "        return None\n",
    "    (x1, y1, x2, y2), handle = window_info\n",
    "    # 截图\n",
    "    grab_image = ImageGrab.grab(bbox=(x1, y1, x2, y2))\n",
    "\n",
    "    return (x1, y1, x2, y2), grab_image\n",
    "\n",
    "#图像相似判断函数，返回相似的概率\n",
    "def template_match(template, image):\n",
    "    # 确保模板和图像都是灰度图并且具有相同的深度\n",
    "    if template.dtype != image.dtype:\n",
    "        template = template.astype(image.dtype)\n",
    "    \n",
    "    result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, max_val, _, _ = cv2.minMaxLoc(result)\n",
    "    return max_val\n",
    "\n",
    "def template_matching(target_image, template_image, ori_width, ori_height):\n",
    "    # 将图像转换为uint8类型\n",
    "    target_image = (target_image * 255).astype(np.uint8)\n",
    "    template_image = (template_image * 255).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    # 原始模板匹配\n",
    "    result_original = cv2.matchTemplate(target_image, template_image, cv2.TM_CCOEFF_NORMED)\n",
    "    #获取翻转前匹配程度最高的位置\n",
    "    _, max_val_original, _, max_loc_original = cv2.minMaxLoc(result_original)\n",
    "    \n",
    "    # 翻转后的模板匹配\n",
    "    template_image_flipped = cv2.flip(template_image, flipCode=1)\n",
    "    result_flipped = cv2.matchTemplate(target_image, template_image_flipped, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    #获取翻转后匹配程度最高的位置\n",
    "    _, max_val_flipped, _, max_loc_flipped = cv2.minMaxLoc(result_flipped)\n",
    "    \n",
    "    # 根据max_val选择使用哪个匹配结果\n",
    "    if max_val_original > max_val_flipped:\n",
    "        max_val = max_val_original\n",
    "        max_loc = max_loc_original\n",
    "        template_used = 'original'\n",
    "    else:\n",
    "        max_val = max_val_flipped\n",
    "        max_loc = max_loc_flipped\n",
    "        template_used = 'flipped'\n",
    "        template_image = template_image_flipped  # 使用翻转后的模板来可视化\n",
    "    \n",
    "    \n",
    "    h, w = template_image.shape\n",
    "    top_left = max_loc\n",
    "    center_point = (top_left[0] + w//2, top_left[1] + h//2)\n",
    "    \n",
    "    # 输出匹配结果图像\n",
    "    matched_image = target_image.copy()\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(matched_image, top_left, bottom_right, 255, 2)\n",
    "    \n",
    "    return center_point\n",
    "\n",
    "#返回template图在target图的坐标位置\n",
    "def transparent_template_matching(target_image, template_image, ori_width, ori_height):\n",
    "    \n",
    "    target_image = cv2.cvtColor(np.array(target_image), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    template_alpha = template_image[:, :, 3]  # 获取alpha通道\n",
    "    template_image = cv2.cvtColor(template_image[:, :, :3], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask =  template_alpha\n",
    "    \n",
    "    \n",
    "    # 原始模板匹配\n",
    "    result_original = cv2.matchTemplate(target_image, template_image, cv2.TM_CCOEFF_NORMED,mask=mask)\n",
    "    #获取翻转前匹配程度最高的位置\n",
    "    _, max_val_original, _, max_loc_original = cv2.minMaxLoc(result_original)\n",
    "    \n",
    "    # 翻转后的模板匹配\n",
    "    template_image_flipped = cv2.flip(template_image, flipCode=1)\n",
    "    result_flipped = cv2.matchTemplate(target_image, template_image_flipped, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    #获取翻转后匹配程度最高的位置\n",
    "    _, max_val_flipped, _, max_loc_flipped = cv2.minMaxLoc(result_flipped)\n",
    "    \n",
    "    # 根据max_val选择使用哪个匹配结果\n",
    "    if max_val_original > max_val_flipped:\n",
    "        max_val = max_val_original\n",
    "        max_loc = max_loc_original\n",
    "        template_used = 'original'\n",
    "    else:\n",
    "        max_val = max_val_flipped\n",
    "        max_loc = max_loc_flipped\n",
    "        template_used = 'flipped'\n",
    "        template_image = template_image_flipped  # 使用翻转后的模板来可视化\n",
    "    \n",
    "    \n",
    "    h, w = template_image.shape\n",
    "    top_left = max_loc\n",
    "    center_point = (top_left[0] + w//2, top_left[1] + h//2)\n",
    "    \n",
    "    # 输出匹配结果图像\n",
    "    matched_image = target_image.copy()\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(matched_image, top_left, bottom_right, 255, 2)\n",
    "    \n",
    "    return center_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56a3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 询问用户是否需要加载模型\n",
    "load_model = 'y'\n",
    "\n",
    "#第一次抓取并锁定位置\n",
    "(x1, y1, x2, y2), img = fetch_image_first(\"test wanna Medium\")\n",
    "\n",
    "#存储胜利截图和死亡截图\n",
    "#grab_image = ImageGrab.grab(bbox=(x1, y1, x2, y2))\n",
    "#grab_image.save('victory_template.png')\n",
    "\n",
    "#记录初始图片的大小和高度\n",
    "ori_width=x2-x1\n",
    "ori_height=y2-y1\n",
    "\n",
    "#获得终点图片\n",
    "endpoint_image_path = 'endpoint.png'\n",
    "endpoint_image = Image.open(endpoint_image_path)\n",
    "endpoint_image = endpoint_image.convert('L')\n",
    "endpoint_image= np.array(endpoint_image) / 255.0\n",
    "endpoint_loc=(0,0)\n",
    "\n",
    "\n",
    "#获得人物图片\n",
    "character_image_path = 'character.png'\n",
    "# character_image = Image.open(character_image_path)\n",
    "# character_image = character_image.convert('L')\n",
    "# character_image= np.array(character_image) / 255.0\n",
    "character_image = cv2.imread(character_image_path, cv2.IMREAD_UNCHANGED)\n",
    "character_loc=(0,0)\n",
    "\n",
    "# 检测探测位置函数是否好使\n",
    "# tem_image_path = 'death_template.PNG'\n",
    "# tem_image = Image.open(tem_image_path)\n",
    "# tem_image = tem_image.convert('L')\n",
    "# tem_image= np.array(tem_image) / 255.0\n",
    "\n",
    "# center_point = template_matching(tem_image, endpoint_image,  ori_width, ori_height)\n",
    "# print(f\"Center point: {center_point}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7429796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def select_file_and_return_filename():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # 隐藏主窗口\n",
    "\n",
    "    file_path = filedialog.askopenfilename()  # 打开文件选择对话框并获取所选文件的路径\n",
    "\n",
    "    if file_path:\n",
    "        file_name = file_path.split(\"/\")[-1]  # 获取文件名（假设路径使用斜杠分隔）\n",
    "        return file_name\n",
    "    else:\n",
    "        return None  # 如果用户取消选择，则返回None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380ca6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model=='y':\n",
    "    model_training_file = select_file_and_return_filename()\n",
    "    target_training_file = select_file_and_return_filename()\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27421b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义 DQN 模型\n",
    "# class DQN(nn.Module):\n",
    "#     def __init__(self, input_shape, num_actions):\n",
    "#         super(DQN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "#         self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "#         self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "#         self.fc2 = nn.Linear(512, num_actions)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.conv1(x))\n",
    "#         x = torch.relu(self.conv2(x))\n",
    "#         x = torch.relu(self.conv3(x))\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         return self.fc2(x)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.flatten_size = self._get_conv_output(input_shape)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_size, 512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, num_actions)\n",
    "        \n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "        output_feat = self._forward_features(input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        is_single_input = (x.size(0) == 1)\n",
    "        if is_single_input:\n",
    "            self.eval()\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        if is_single_input:\n",
    "            self.train()\n",
    "        return x\n",
    "\n",
    "\n",
    "# 经验回放缓冲区\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# 环境交互\n",
    "def get_state():\n",
    "    \n",
    "    img =  ImageGrab.grab(bbox=(x1, y1, x2, y2))\n",
    "    #在这里更新人物的位置和终点的位置信息\n",
    "    temp_image = img.convert('L')\n",
    "    temp_image= np.array(temp_image) / 255.0\n",
    "    endpoint_loc = template_matching(temp_image, endpoint_image,  ori_width, ori_height)\n",
    "    character_loc = transparent_template_matching(img, character_image,  ori_width, ori_height)\n",
    "    \n",
    "    if img is not None:\n",
    "        img = img.resize((84, 84)).convert('L')\n",
    "        return np.array(img) / 255.0,character_loc, endpoint_loc\n",
    "    \n",
    "    return None,None,None\n",
    "\n",
    "\n",
    "# 选择动作函数\n",
    "def select_action(state, epsilon, mask, num_actions):\n",
    "\n",
    "    mask = mask.view(1, -1)\n",
    "    if random.random() > epsilon:\n",
    "        with torch.no_grad():\n",
    "            state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).unsqueeze(0).cuda()\n",
    "            q_values = model(state)\n",
    "            q_values = q_values * mask\n",
    "            # 只在 mask 为 1 的动作中选取 Q 值最大的动作\n",
    "            valid_q_values = q_values[mask == 1]\n",
    "            \n",
    "            device = mask.device  # 获取mask张量所在的设备（假设在GPU上）\n",
    "            valid_actions = torch.arange(num_actions, device=device)[mask.view(-1) == 1]\n",
    "            \n",
    "            max_valid_action = valid_q_values.argmax().item()\n",
    "            action = valid_actions[max_valid_action].item()\n",
    "            return q_values, action\n",
    "    else:\n",
    "        masked_actions = mask.view(-1).nonzero(as_tuple=True)[0].tolist()  # 将mask展平为1D，然后获取非零索引\n",
    "\n",
    "        action = random.choice(masked_actions)  # 随机从有效的动作中选取执行\n",
    "\n",
    "        return None,action\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# # 测试 get_state 函数\n",
    "# state, a, b= get_state()\n",
    "\n",
    "# if state is not None:\n",
    "#     print(a)\n",
    "#     print(b)\n",
    "#     print(\"State shape:\", state.shape)\n",
    "#     print(\"State dtype:\", state.dtype)\n",
    "#     img = Image.fromarray((state * 255).astype(np.uint8))  # 转换回图片以查看效果\n",
    "#     img.show()\n",
    "\n",
    "\n",
    "bins=16\n",
    "#全局变量记录所有的状态只记录最新的10000条\n",
    "visited_states = deque(maxlen=100000)  \n",
    "\n",
    "\n",
    "# 量化状态函数\n",
    "def quantize_state(state, bins=16):\n",
    "    # 将状态量化为指定的bins数量\n",
    "    state_quantized = np.digitize(state, np.linspace(0, 255, bins))\n",
    "    return state_quantized\n",
    "\n",
    "# 计算状态的哈希值\n",
    "def hash_state(state):\n",
    "    state_bytes = state.tobytes()\n",
    "    state_hash = hashlib.sha256(state_bytes).hexdigest()\n",
    "    return state_hash\n",
    "\n",
    "\n",
    "def compute_reward(state,character_loc,endpoint_loc, next_state, next_character_loc, next_endpoint_loc):\n",
    "    # 计算并返回奖励值\n",
    "    reward = -10\n",
    "    \n",
    "    next_state_quantized = quantize_state(next_state, bins)\n",
    "    next_state_hash = hash_state(next_state_quantized)\n",
    "    \n",
    "    if next_state_hash not in visited_states:\n",
    "        reward += 10  # 探索新状态的奖励\n",
    "        visited_states.append(next_state_hash) \n",
    "    else:\n",
    "        reward -= 100  # 重复状态的惩罚\n",
    "    \n",
    "    \n",
    "    # 计算距离\n",
    "    current_distance = np.linalg.norm(np.array(character_loc) - np.array(endpoint_loc))\n",
    "    next_distance = np.linalg.norm(np.array(next_character_loc) - np.array(next_endpoint_loc))\n",
    "        \n",
    "    # 示例：根据某种条件设置奖励\n",
    "    if check_if_victory(next_state):\n",
    "        reward += 10000  # 通关奖励\n",
    "    elif check_if_death(next_state):\n",
    "        reward -= 10000  # 死亡惩罚\n",
    "    \n",
    "    return current_distance,next_distance,reward\n",
    "\n",
    "def compute_distance_reward(last_d1, d1):\n",
    "    # 计算移动距离的差值\n",
    "    distance_diff = last_d1 - d1  # 如果last_d1 > d1，说明靠近目标，应奖励\n",
    "    \n",
    "    # 根据差值计算奖励\n",
    "    if distance_diff > 0:\n",
    "        # 距离减少，给予正面奖励\n",
    "        reward = 10 * distance_diff\n",
    "    elif distance_diff < 0:\n",
    "        # 距离增加，给予负面奖励\n",
    "        reward = -10 * abs(distance_diff)\n",
    "    else:\n",
    "        # 距离没有变化\n",
    "        reward = 0\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd172537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 动作定义\n",
    "ACTIONS = ['left', 'right', 'shift', 're_left','re_right','re_shift','none_op']\n",
    "KEY_CODES = [0x25, 0x27, 0x10, 0x52]  # 左箭头键、右箭头键、Shift键、'R'键\n",
    "\n",
    "def press_key(hex_key_code):\n",
    "    win32api.keybd_event(hex_key_code, 0, 0, 0)\n",
    "\n",
    "def release_key(hex_key_code):\n",
    "    win32api.keybd_event(hex_key_code, 0, win32con.KEYEVENTF_KEYUP, 0)\n",
    "\n",
    "\n",
    "def release_all_keys():\n",
    "    for key_code in KEY_CODES:\n",
    "        release_key(key_code)\n",
    "        \n",
    "def perform_reset():\n",
    "    press_key(0x52)  # 'R' 键\n",
    "    time.sleep(0.1)\n",
    "    release_key(0x52)\n",
    "    release_all_keys()  # 释放所有按键\n",
    "    \n",
    "def perform_jump():\n",
    "    press_key(0x10)  # 'SHIFT' 键\n",
    "    time.sleep(0.5)\n",
    "    release_key(0x10)\n",
    "    release_all_keys()  # 释放所有按键\n",
    "    \n",
    "def perform_attack():\n",
    "    press_key(0x2C)  # 'Z' 键\n",
    "    time.sleep(0.1)\n",
    "    release_key(0x2C)\n",
    "    #release_all_keys()  # 释放所有按键\n",
    "    \n",
    "# #最开始的想法\n",
    "# def perform_action(action):\n",
    "#     # 执行动作\n",
    "#     if action == 0:  # 左移\n",
    "#         press_key(0x25)  # 左箭头键\n",
    "#         time.sleep(0.1)\n",
    "#         release_key(0x25)\n",
    "#     elif action == 1:  # 右移\n",
    "#         press_key(0x27)  # 右箭头键\n",
    "#         time.sleep(0.1)\n",
    "#         release_key(0x27)\n",
    "#     elif action == 2:  # Shift\n",
    "#         press_key(0x10)  # Shift 键\n",
    "#         time.sleep(0.1)\n",
    "#         release_key(0x10)\n",
    "#     elif action == 3:  # 长按 Shift\n",
    "#         press_key(0x10)  # Shift 键\n",
    "#         time.sleep(0.6)\n",
    "#         release_key(0x10)\n",
    "   \n",
    "    \n",
    "def perform_action(state, character_loc, endpoint_loc,action):\n",
    "    # 执行动作\n",
    "    global state_action\n",
    "    \n",
    "    if action == 0:  # 按下左键\n",
    "        press_key(0x25)  # 左箭头键\n",
    "        time.sleep(0.05)\n",
    "        state_action[0]=1\n",
    "    elif action == 1:  # 按下右键\n",
    "        press_key(0x27)  # 右箭头键\n",
    "        time.sleep(0.05)\n",
    "        state_action[1]=1\n",
    "    elif action == 2:  # 按下Shift键\n",
    "        press_key(0x10)  # Shift键\n",
    "        time.sleep(0.05)\n",
    "        state_action[2]=1\n",
    "        \n",
    "    elif action == 3:  # 松开左键\n",
    "        release_key(0x25)  # 左箭头键\n",
    "        time.sleep(0.05)\n",
    "        state_action[0]=0\n",
    "    elif action == 4:  # 松开右键\n",
    "        release_key(0x27)  # 右箭头键\n",
    "        time.sleep(0.05)\n",
    "        state_action[1]=0\n",
    "    elif action == 5:  # 松开Shift键\n",
    "        release_key(0x10)  # Shift键\n",
    "        time.sleep(0.05)\n",
    "        state_action[2]=0\n",
    "    elif action ==6: #不操作\n",
    "        time.sleep(0.05)\n",
    "        pass\n",
    "    \n",
    "    # 获取下一状态\n",
    "    next_state, next_character_loc, next_endpoint_loc= get_state()\n",
    "    \n",
    "    # 计算奖励 (这里你需要根据你的游戏环境定义奖励)\n",
    "    \n",
    "    d1,d2,reward = compute_reward(state,character_loc,endpoint_loc, next_state, next_character_loc, next_endpoint_loc)\n",
    "\n",
    "    # 判断是否结束 (根据你的游戏逻辑定义终止条件)\n",
    "    done = check_if_done(next_state, reward)\n",
    "\n",
    "    return d1,d2,reward, next_state, next_character_loc, next_endpoint_loc,done\n",
    "\n",
    "\n",
    "def update_mask(state_action, mask, num_actions):\n",
    "    # 重置 mask\n",
    "    mask.fill_(0)  # 将所有元素重置为 0\n",
    "\n",
    "    # 根据 state_action 更新 mask\n",
    "    if state_action[0] == 1:  # 左键被按下\n",
    "        mask[0, 3] = 1  # 允许松开左键\n",
    "        mask[0, 1] = 0  # 禁止按下右键\n",
    "    else:\n",
    "        mask[0, 0] = 1  # 允许按下左键\n",
    "    \n",
    "    if state_action[1] == 1:  # 右键被按下\n",
    "        mask[0, 4] = 1  # 允许松开右键\n",
    "        mask[0, 0] = 0  # 禁止按下左键\n",
    "    else:\n",
    "        mask[0, 1] = 1  # 允许按下右键\n",
    "    \n",
    "    if state_action[2] == 1:  # Shift键被按下\n",
    "        mask[0, 5] = 1  # 允许松开Shift键\n",
    "    else:\n",
    "        mask[0, 2] = 1  # 允许按下Shift键\n",
    "        \n",
    "    # 确保左键和右键不能同时按下\n",
    "    if state_action[0] == 1 or state_action[1] == 1:\n",
    "        mask[0, 0] = 0  # 禁止按下左键\n",
    "        mask[0, 1] = 0  # 禁止按下右键\n",
    "    mask[0, 6] = 1  # 永远允许不动操作\n",
    "    return mask\n",
    "\n",
    "# # 测试 perform_action 函数\n",
    "# action = 0  # 示例动作\n",
    "# reward, next_state, done = perform_action(action)\n",
    "# print(\"Reward:\", reward)\n",
    "# print(\"Next state shape:\", next_state.shape)\n",
    "# print(\"Done:\", done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3e9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_victory(state):\n",
    "    # 加载胜利状态模板图像并转换为灰度图像\n",
    "    victory_template = Image.open('victory_template.png').convert('L')\n",
    "    # 调整模板图像大小以匹配 state 的大小\n",
    "    victory_template = victory_template.resize((state.shape[1], state.shape[0]))\n",
    "    resized_victory_template = np.array(victory_template) / 255.0\n",
    "\n",
    "    match_value = template_match((resized_victory_template * 255).astype(np.uint8), (state * 255).astype(np.uint8))\n",
    "    return match_value > 0.9  # 设置一个阈值\n",
    "\n",
    "def check_if_death(state):\n",
    "    # 加载死亡状态模板图像并转换为灰度图像\n",
    "    death_template = Image.open('death_template.png').convert('L')\n",
    "    # 调整模板图像大小以匹配 state 的大小\n",
    "    death_template = death_template.resize((state.shape[1], state.shape[0]))\n",
    "    resized_death_template = np.array(death_template) / 255.0\n",
    "    match_value = template_match((resized_death_template * 255).astype(np.uint8), (state * 255).astype(np.uint8))\n",
    "    return match_value > 0.95  # 设置一个阈值\n",
    "\n",
    "\n",
    "def check_if_done(state,reward):\n",
    "    # 判断是否结束\n",
    "    # 这里你需要根据你的游戏逻辑定义终止条件\n",
    "    done = 0\n",
    "    # 示例：根据某种条件设置结束标志\n",
    "    if check_if_death(state):\n",
    "        print(\"death\")\n",
    "        done = 1\n",
    "    elif check_if_victory(state):\n",
    "        print(\"win\")\n",
    "        done = 2\n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5886d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import random\n",
    "import hashlib\n",
    "root = tk.Tk()\n",
    "root.title(\"Action and Reward Display\")\n",
    "root.geometry(\"500x300+0+0\")\n",
    "\n",
    "# 标签来显示action和reward\n",
    "action_label_text = tk.Label(root, text=\"Action: None\")\n",
    "action_label_text.place(x=5, y=10)\n",
    "\n",
    "reward_label_text = tk.Label(root, text=\"Reward: None\")\n",
    "reward_label_text.place(x=5, y=40)\n",
    "\n",
    "# 标签来显示mask和state_action\n",
    "mask_label_text = tk.Label(root, text=\"Mask: None\")\n",
    "mask_label_text.place(x=5, y=70)\n",
    "\n",
    "state_action_label_text = tk.Label(root, text=\"State Action: None\")\n",
    "state_action_label_text.place(x=5, y=100)\n",
    "\n",
    "# 标签来显示Q values\n",
    "qvalues_label_text = tk.Label(root, text=\"Q Values: None\")\n",
    "qvalues_label_text.place(x=5, y=130)\n",
    "\n",
    "distance_label_text = tk.Label(root, text=\"Last Disatance: None\")\n",
    "distance_label_text.place(x=5, y=160)\n",
    "\n",
    "distance2_label_text = tk.Label(root, text=\"Update Disatance: None\")\n",
    "distance2_label_text.place(x=5, y=190)\n",
    "\n",
    "# 动作标签列表\n",
    "action_labels = [\"按←\",  \"按→\", \"按↑\", \"松←\", \"松→\",\"松↑\",\"停□\"]\n",
    "\n",
    "\n",
    "# 更新显示的函数\n",
    "\n",
    "# def update_display(action, reward):\n",
    "#     action_label_text.config(text=f\"Action: {action_labels[action]}\")\n",
    "#     reward_label_text.config(text=f\"Reward: {reward:.2f}\")\n",
    "#     root.update()\n",
    "\n",
    "\n",
    "def update_display(action, reward, mask, state_action,qvalues,distance,d2):\n",
    "    action_label_text.config(text=f\"Action: {action_labels[action]}\")\n",
    "    reward_label_text.config(text=f\"Reward: {reward:.2f}\")\n",
    "    mask_label_text.config(text=f\"Mask: {mask.cpu().numpy()}\")\n",
    "    state_action_label_text.config(text=f\"State Action: {state_action}\")\n",
    "    if qvalues== None:\n",
    "        qvalues_label_text.config(text=f\"Q Values: None\")\n",
    "    else:\n",
    "        qvalues_label_text.config(text=f\"Q Values: {np.array2string(qvalues.cpu().numpy(), precision=2, separator=',')}\")\n",
    "    \n",
    "    distance_label_text.config(text=f\"Last Disatance: {distance}\")\n",
    "    distance2_label_text.config(text=f\"Update Disatance: {d2}\")\n",
    "        \n",
    "    root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9dabc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 超参数\n",
    "num_actions = 7\n",
    "capacity = 10000\n",
    "batch_size = 32\n",
    "gamma = 0.99\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.01\n",
    "epsilon_decay = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 初始化\n",
    "input_shape = (1, 84, 84)\n",
    "model = DQN(input_shape, num_actions).cuda()\n",
    "target_model = DQN(input_shape, num_actions).cuda()\n",
    "target_model.load_state_dict(model.state_dict())\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 使用 StepLR 调度器动态调整学习率\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.95)\n",
    "\n",
    "\n",
    "replay_buffer = ReplayBuffer(capacity)\n",
    "\n",
    "\n",
    "if load_model.lower() == 'y':\n",
    "    # 加载模型参数\n",
    "    if os.path.exists(model_training_file):\n",
    "        model.load_state_dict(torch.load(model_training_file))\n",
    "        model.eval()\n",
    "    else:\n",
    "        print(f\"Model parameters file '{model_training_file}' not found.\")\n",
    "        \n",
    "    if os.path.exists(target_training_file):\n",
    "        target_model.load_state_dict(torch.load(target_training_file))\n",
    "        target_model.eval()\n",
    "    else:\n",
    "        print(f\"Model parameters file '{target_training_file}' not found.\")\n",
    "else:\n",
    "    print(\"Model parameters not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "\n",
    "# 设置扰动方向的范围\n",
    "delta_range = 3.0\n",
    "num_points = 50\n",
    "deltas = np.linspace(-delta_range, delta_range, num_points)\n",
    "\n",
    "# 初始化奖励数据\n",
    "rewards = np.zeros((num_points, num_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb96255",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e26a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 执行实验并收集数据\n",
    "for i, delta1 in enumerate(deltas):\n",
    "    for j, delta2 in enumerate(deltas):\n",
    "        perturbed_model = model.state_dict()\n",
    "        for name, param in model.named_parameters():\n",
    "            # 在CUDA上生成与参数相同形状的扰动\n",
    "            direction1 = torch.randn_like(param).cuda()\n",
    "            direction2 = torch.randn_like(param).cuda()\n",
    "            direction1 /= torch.norm(direction1)\n",
    "            direction2 /= torch.norm(direction2)\n",
    "            \n",
    "            # 将扰动添加到参数中\n",
    "            perturbation = delta1 * direction1 + delta2 * direction2\n",
    "            perturbed_model[name].copy_(param + perturbation)\n",
    "        model.load_state_dict(perturbed_model)\n",
    "        \n",
    "        # 运行多个实验取平均奖励\n",
    "        total_reward = 0\n",
    "        num_episodes = 5\n",
    "        for _ in range(num_episodes):\n",
    "            #重新初始化\n",
    "            state_action=[0,0,0,0]\n",
    "            mask = torch.ones(1, num_actions).cuda()  # 初始化 mask\n",
    "            time.sleep(1)\n",
    "            perform_reset()\n",
    "            state, character_loc, endpoint_loc = get_state()\n",
    "        \n",
    "            total_reward = 0\n",
    "            last_d1=-1\n",
    "            \n",
    "            done = False\n",
    "            while not done:\n",
    "                mask = update_mask(state_action, mask, num_actions)  # Update mask based on the action taken\n",
    "            \n",
    "                qvalues,action = select_action(state, epsilon, mask, num_actions)\n",
    "            \n",
    "                # 执行动作并获取奖励\n",
    "                d1,d2,reward, state, next_character_loc, next_endpoint_loc, done = perform_action(state, character_loc, endpoint_loc, action)\n",
    "                \n",
    "                total_reward += reward\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        rewards[i, j] = total_reward / num_episodes\n",
    "\n",
    "# 绘制奖励面\n",
    "X, Y = np.meshgrid(deltas, deltas)\n",
    "Z = rewards\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "ax.set_xlabel('Delta 1')\n",
    "ax.set_ylabel('Delta 2')\n",
    "ax.set_zlabel('Mean Reward')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301209a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
